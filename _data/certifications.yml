- title: "ASHBY Prize in Computational Science Hackathon: 3rd Place & Best Presentation"
  issuer: "Center for Artificial Intelligence Innovation at the National Center for Supercomputing Applications"
  date: "May 2024"
  link: "https://ai.ncsa.illinois.edu/news-events/2024/05/2024-hackathon-winners-announced/"
  description: >
    Awarded 3rd place (out of 50 participants) in the ASHBY Prize in Computational Science Hackathon, a competition focused on using LLMs as a front-end to computational workflows. We developed an end-to-end agent-based system capable of Retrieval Augmented Generation (RAG), integrated with an API-based model GPT-4 and a locally-hosted Llama 3 model. Received best presentation recognition for our real-time demonstration and delivery!

- title: "Illinois Statistics Datathon 2024: 4th Place"
  issuer: "Department of Statistics, UIUC, with Synchrony Financial"
  date: "April 2024"
  link: "https://stat.illinois.edu/datathon"
  description: >
    Awarded 4th place (out of 345 participants) in the Illinois Statistics Datathon 2024. With my team, we performed extensive data pre-processing, exploratory data analysis (EDA), and feature engineering to identify and build key features for Synchrony’s Interactive Voice Response (IVR) System, a “real-world” dataset with millions of observations. We employed Logistic Regression (for its interpretability) to evaluate measured and engineered features’ effects on reducing the number of “floored” calls, effectively resulting in a data-driven decision, with a savings potential of $300,000 per 1% reduction of calls. You can read about our experience on this [post](https://www.linkedin.com/feed/update/urn:li:activity:7180625594085253120/).

- title: "Data Parallelism: How to Train Deep Learning Models on Multiple GPUs"
  issuer: "NVIDIA"
  date: "March 2024"
  link: "https://learn.nvidia.com/certificates?id=e01935a5797049a6a71f3188d7a3e95f"
  description: >
    Certifies competence in the completion of Workshop/Data Parallelism: How to Train Deep Learning Models on Multiple GPUs. Through this course, I successfully trained and deployed a set of Convolutional Neural Networks on the Fashion MNIST dataset using Python, CUDA, and the DDP library for Distributed Data Parallelism with 4 GPUs. I also applied advanced techniques such as gradual warmup, batch normalization, and the NovoGrad optimizer to enhance model performance and training efficiency. Great experience!


